{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulofreitas-py/IA-Labs/blob/main/Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yob8kLEZeUzF"
      },
      "source": [
        "## Gemini: Connecting to Gemini\n",
        "\n",
        "The Gemini API allows you to connect to Google's most powerful multi-modal model. This example configures your API key and sends an example message to the API and prints a response.\n",
        "\n",
        "Before you start, visit https://aistudio.google.com/app/apikey to create an API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJ2d2cIhcmyw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Configure Gemini API key\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "gemini_api_secret_name = 'GOOGLE_API_KEY'  # @param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "  GOOGLE_API_KEY=userdata.get(gemini_api_secret_name)\n",
        "  genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except userdata.SecretNotFoundError as e:\n",
        "   print(f'Secret not found\\n\\nThis expects you to create a secret named {gemini_api_secret_name} in Colab\\n\\nVisit https://aistudio.google.com/app/apikey to create an API key\\n\\nStore that in the secrets section on the left side of the notebook (key icon)\\n\\nName the secret {gemini_api_secret_name}')\n",
        "   raise e\n",
        "except userdata.NotebookAccessError as e:\n",
        "  print(f'You need to grant this notebook access to the {gemini_api_secret_name} secret in order for the notebook to access Gemini on your behalf.')\n",
        "  raise e\n",
        "except Exception as e:\n",
        "  print(f\"There was an unknown error. Ensure you have a secret {gemini_api_secret_name} stored in Colab and it's a valid key from https://aistudio.google.com/app/apikey\")\n",
        "  raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM1IZNtDdZuq",
        "outputId": "b7eda844-51fc-4a49-f2f6-ea4ff55aff0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain é um framework de código aberto que simplifica o desenvolvimento de aplicações de Inteligência Artificial baseadas em modelos de linguagem grandes (LLMs).  Sua importância no desenvolvimento de apps de IA reside na sua capacidade de conectar LLMs a outras fontes de dados e recursos de computação, permitindo criar aplicações mais robustas, úteis e complexas do que seria possível usando apenas a API de um LLM isoladamente.\\n\\nEm essência, o LangChain atua como uma \"cola\" que conecta diferentes componentes para construir aplicações mais completas.  Isso se traduz em vários benefícios:\\n\\n* **Modularidade:**  Ele permite que você construa aplicações a partir de módulos independentes e reutilizáveis, facilitando o desenvolvimento, manutenção e escalabilidade.  Você pode trocar facilmente um componente por outro, por exemplo, mudando o LLM ou o método de armazenamento de dados, sem ter que reescrever todo o código.\\n\\n* **Integração com múltiplas fontes de dados:** LangChain se integra facilmente a bancos de dados, APIs, arquivos e outras fontes de informação, permitindo que os LLMs acessem e processem informações externas relevantes para a tarefa.  Isso é crucial para que os LLMs não se limitem ao seu conhecimento pré-treinado, mas possam acessar informações atuais e específicas.\\n\\n* **Memória e raciocínio de longo prazo:**  O framework permite a implementação de mecanismos de memória, permitindo que o LLM \"lembre\" de interações passadas durante uma conversa ou uma tarefa complexa.  Isso é fundamental para a construção de chatbots mais inteligentes e sistemas de raciocínio mais sofisticados.\\n\\n* **Cadeias de pensamento (Chains of Thought):** LangChain facilita a criação de \"cadeias de pensamento\", onde um LLM divide um problema complexo em subproblemas menores que são resolvidos sequencialmente, melhorando a capacidade do modelo de resolver problemas mais desafiadores.\\n\\n* **Agentes (Agents):**  Possibilita a construção de agentes que podem tomar decisões autônomas, selecionando e usando diferentes ferramentas para atingir um objetivo específico. Por exemplo, um agente poderia usar um buscador na internet, uma base de dados e um LLM para responder a uma pergunta complexa.\\n\\n**Em resumo:**  O LangChain é importante porque reduz a complexidade do desenvolvimento de aplicações de IA baseadas em LLMs, fornecendo uma estrutura modular e ferramentas para integrar diversas fontes de dados e recursos computacionais.  Isso permite a criação de aplicações mais inteligentes, robustas e úteis, acelerando o desenvolvimento e permitindo que desenvolvedores se concentrem na lógica da aplicação em vez de detalhes de integração.  Sem LangChain, a construção dessas aplicações seria significativamente mais trabalhosa e complexa.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# @title Connect to the API and send an example message\n",
        "\n",
        "text = 'O que é o langchain e porque ele é importante no contexto do desenv de app de IA?' # @param {type: \"string\"}\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "response = chat.send_message(text)\n",
        "response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRrm9P6QDjrB"
      },
      "source": [
        "## Gemini: Creating a prompt\n",
        "\n",
        "This rich example shows how you can create and configure complex prompts for Gemini. It assumes that you've already created an API key at https://aistudio.google.com/app/apikey and added it to your Colab secrets as `GOOGLE_API_KEY` (see the \"Connecting to Gemini\" snippet)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCVoMaiGDjrB",
        "outputId": "39b7a0e3-3adb-47ae-8026-62d9ea61fc87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain é um framework de software de código aberto que simplifica a criação de aplicações usando modelos de linguagem grandes (LLMs)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# @title Create a prompt\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key_name = 'GOOGLE_API_KEY' # @param {type: \"string\"}\n",
        "prompt = 'O que é o langchain?' # @param {type: \"string\"}\n",
        "system_instructions = '' # @param {type: \"string\"}\n",
        "model = 'gemini-2.0-flash-exp' # @param {type: \"string\"} [\"gemini-1.0-pro\", \"gemini-1.5-pro\", \"gemini-1.5-flash\",'gemini-2.0-flash-exp']\n",
        "temperature = 0.55 # @param {type: \"slider\", min: 0, max: 2, step: 0.05}\n",
        "stop_sequence = '.' # @param {type: \"string\"}\n",
        "\n",
        "if model == 'gemini-1.0-pro' and system_instructions is not None:\n",
        "  system_instructions = None\n",
        "  print('\\x1b[31m(WARNING: System instructions ignored, gemini-1.0-pro does not support system instructions)\\x1b[0m')\n",
        "\n",
        "if model == 'gemini-1.0-pro' and temperature > 1:\n",
        "  temperature = 1\n",
        "  print('\\x1b[34m(INFO: Temperature set to 1, gemini-1.0-pro does not support temperature > 1)\\x1b[0m')\n",
        "\n",
        "if system_instructions == '':\n",
        "  system_instructions = None\n",
        "\n",
        "api_key = userdata.get(api_key_name)\n",
        "genai.configure(api_key=api_key)\n",
        "model = genai.GenerativeModel(model, system_instruction=system_instructions)\n",
        "config = genai.GenerationConfig(temperature=temperature, stop_sequences=[stop_sequence])\n",
        "response = model.generate_content(contents=[prompt], generation_config=config)\n",
        "response.text"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}